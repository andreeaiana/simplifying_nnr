# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: mind.yaml
  - override /model: naml.yaml
  - override /callbacks: default.yaml
  - override /logger: many_loggers.yaml
  - override /trainer: gpu.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["naml", "small", "celoss", "lf"]

seed: 42

datamodule:
  size: "small"
  num_workers: 8
  dataset_attributes: ['title', 'abstract']

model:
  supcon_loss: False
  late_fusion: True
  dataset_attributes: ['title', 'abstract', 'category', 'subcategory']
  pretrained_word_embeddings_path: ${paths.data_dir}MIND${datamodule.size}_train/pretrained_word_embeddings_all.npy
  num_categories: 281

trainer:
  max_epochs: 25

logger:
  wandb:
    name: "naml_small_celoss_lf_tasc_s42"
    tags: ${tags}
    group: "small"
